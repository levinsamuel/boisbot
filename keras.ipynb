{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pathlib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today is day one of the biggest project ive ever tried. it is called 17776 httpswww.sbnation.coma17776-football ',\n",
       " 'congratulations to all red sox fans who are staying up past three in the morning terrified that your unbelievably successful team wont win every game. you are now an honorary fox news grandpa',\n",
       " 'welcome to college football saturday',\n",
       " '.mlb 13th inning, suckers! im taking you rubes for at least four free innings of baseball. beware of jon the boring content bandit',\n",
       " 'things ive done in red dead 2 so far_- fought bear_- murdered by alligator_- killed 10 lawmen after being falsely accused of murder_- called a guy a coward and he ran away_- sat by a lake, reflected_- lassoed a guy off his horse, hogtied him, put him back on his own horse, left',\n",
       " 'red dead redemption 2 is a wonderful game. sending a fruit basket to the person who made it',\n",
       " 'twitter offered me extended logoff time if i volunteered to show up at the mall in my twitter uniform and recruit new posters',\n",
       " 'metacritic is great. it sidesteps the great gaming journalism and highlights all the stuff written like red dead redemption 2 is of a masterpiece. it is most definitely having a moment. when speaking of games it is whence a landmark.',\n",
       " 'working on stuff',\n",
       " 'the reason red dead redemption 2 is only a 97 on metacritic is that i gave it a 0. i just dont really like world war ii stuff']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/5mintweets.txt') as f:\n",
    "    tweetstr=f.read()\n",
    "\n",
    "tweets=tweetstr.split('\\n')\n",
    "tweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count characters and create map to integers\n",
    "chars=sorted(set(tweetstr))\n",
    "# Number of distinct characters\n",
    "chardict=len(chars)\n",
    "charcount=len(tweetstr)\n",
    "char_map={c:i for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  82090\n"
     ]
    }
   ],
   "source": [
    "# Create sub sequences of a fixed length to feed to network\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, charcount - seq_length):\n",
    "    seq_in = tweetstr[i:i + seq_length]\n",
    "    seq_out = tweetstr[i + seq_length]\n",
    "    dataX.append([char_map[char] for char in seq_in])\n",
    "    dataY.append(char_map[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(chardict)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "pathlib.Path(\"out/checkpoints\").mkdir(exist_ok=True)\n",
    "filepath=\"out/checkpoints/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82090/82090 [==============================] - 408s 5ms/step - loss: 3.0283\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.02831, saving model to out/checkpoints/weights-01-3.0283.hdf5\n",
      "Epoch 2/20\n",
      "82090/82090 [==============================] - 403s 5ms/step - loss: 2.9023\n",
      "\n",
      "Epoch 00002: loss improved from 3.02831 to 2.90231, saving model to out/checkpoints/weights-02-2.9023.hdf5\n",
      "Epoch 3/20\n",
      "82090/82090 [==============================] - 399s 5ms/step - loss: 2.8533\n",
      "\n",
      "Epoch 00003: loss improved from 2.90231 to 2.85332, saving model to out/checkpoints/weights-03-2.8533.hdf5\n",
      "Epoch 4/20\n",
      "82090/82090 [==============================] - 409s 5ms/step - loss: 2.8223\n",
      "\n",
      "Epoch 00004: loss improved from 2.85332 to 2.82226, saving model to out/checkpoints/weights-04-2.8223.hdf5\n",
      "Epoch 5/20\n",
      "82090/82090 [==============================] - 487s 6ms/step - loss: 2.8040\n",
      "\n",
      "Epoch 00005: loss improved from 2.82226 to 2.80401, saving model to out/checkpoints/weights-05-2.8040.hdf5\n",
      "Epoch 6/20\n",
      "82090/82090 [==============================] - 500s 6ms/step - loss: 2.7823\n",
      "\n",
      "Epoch 00006: loss improved from 2.80401 to 2.78230, saving model to out/checkpoints/weights-06-2.7823.hdf5\n",
      "Epoch 7/20\n",
      "64384/82090 [======================>.......] - ETA: 1:42 - loss: 2.7715"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
